{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.read_csv(\"sonar.all-data.csv\", header=None)\n",
    "\n",
    "y_df = main_df[60] \n",
    "targes_label = {'M': 1,'R': -1} \n",
    "targes_df = np.array([targes_label[item] for item in y_df] )\n",
    "\n",
    "inputs_df = main_df.drop(60, axis=1)\n",
    "inputs_df = main_df.drop(60, axis=1) \n",
    "x0 = np.ones(( inputs_df.shape[0], 1)) \n",
    "X = np.concatenate((x0, inputs_df), axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, targes_df, test_size=0.30, \n",
    "random_state=42)\n",
    "\n",
    "X_test1 = X_test[:, 1:len(X_test)]\n",
    "print(X_test1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 145)\n",
      "(1, 60) (1,)\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Cach 2: Xây dựng phương pháp giải bài toán tối ưu không ràng buộc\n",
    "Z = X_train.T\n",
    "print(Z.shape)\n",
    "\n",
    "C = 200\n",
    "lam = 1./C\n",
    "\n",
    "def cost(w):\n",
    "    u = w.T.dot(Z) # as in (23) \n",
    "    return (np.sum(np.maximum(0, 1 - u)) + .5*lam*np.sum(w*w)) - .5*lam*w[-1]*w[-1] # no bias \n",
    "\n",
    "def grad(w): \n",
    "    u = w.T.dot(Z) # as in (23) \n",
    "    H = np.where(u < 1)[1] \n",
    "    ZS = Z[:, H] \n",
    "    g = (-np.sum(ZS, axis = 1, keepdims = True) + lam*w) \n",
    "    g[-1] -= lam*w[-1] # no weight decay on bias \n",
    "    return g\n",
    "\n",
    "eps = 1e-6 \n",
    "def num_grad(w): \n",
    "    g = np.zeros_like(w) \n",
    "    for i in range(len(w)): \n",
    "        wp = w.copy() \n",
    "        wm = w.copy() \n",
    "        wp[i] += eps \n",
    "        wm[i] -= eps  \n",
    "        g[i] = (cost(wp) - cost(wm))/(2*eps) \n",
    "    return g  \n",
    " \n",
    "w0 = np.random.randn(Z.shape[0], 1)  \n",
    "g1 = grad(w0) \n",
    "g2 = num_grad(w0) \n",
    "diff = np.linalg.norm(g1 - g2) \n",
    "# print('Gradient different: %f' %diff) \n",
    "\n",
    "def grad_descent(w0, eta): \n",
    "    w = w0 \n",
    "    it = 0  \n",
    "    while it < 100000: \n",
    "        it = it + 1 \n",
    "        g = grad(w) \n",
    "        w -= eta*g \n",
    "        # if (it % 10000) == 1: \n",
    "            # print('iter %d' %it + ' cost: %f' %cost(w)) \n",
    "        if np.linalg.norm(g) < 1e-5: \n",
    "            break  \n",
    "    return w  \n",
    "w0 = np.random.randn(Z.shape[0], 1)  \n",
    "w = grad_descent(w0, 0.001) \n",
    "w_hinge = w[:-1].reshape(-1, 1) \n",
    "b_hinge = w[-1] \n",
    "print(w_hinge.T.shape, b_hinge.shape)\n",
    "\n",
    "\n",
    "y_pred2 = np.sign(np.dot(w_hinge.T, X_test1)+ b_hinge)\n",
    "print(y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
